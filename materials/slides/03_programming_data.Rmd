---
title: "Big Data Analytics"
subtitle: 'Lecture 3:<br>Programming with Data'
author: "Prof. Dr. Ulrich Matter"
date: "05/03/2020"
output:
  ioslides_presentation:
    css: ../../style/ioslides.css
    template: ../../style/nologo_template.html
logo: ../img/logo.png
bibliography: ../references/bigdata.bib
---

```{r set-options, echo=FALSE, cache=FALSE, purl=FALSE}
options(width = 100)
library(knitr)
```


# Updates

## Build groups for group examination

- Teams of 2-3.
- Forum on StudyNet.
- All team members must have a GitHub account.

## Group examination

- Analysis of (big) dataset in R.
- Report on analysis in R Markdown.
- Conceptual questions.
- Collaborate, hand-in, feedback via GitHub.




## Notes, Slides, Code, et al.

- [umatter.github.io/courses](https://umatter.github.io/courses.html)
- [github.com/umatter/BigData](https://github.com/umatter/BigData)
- [StudyNet](https://fronter.com/unisg/main.phtml)

## Suggested Learning Procedure

- Clone/fork the course's GitHub-repository.
- During class, use the Rmd-file of the slide-set as basis for your notes.
- After class, enrich/merge/extend your notes with the lecture notes.

## Goals for Today

1. Get familiar with the tools.
2. Get overview over key aspects of programming with big data in R.
3. First hands-on experience with big data statistics.



# Recap of Week 2




## Components of a computing environment
 

```{r cpu2, echo=FALSE, out.width = "25%", fig.align='center', purl=FALSE}
include_graphics("../img/03_cpu.jpg")
```

```{r ram2, echo=FALSE, out.width = "25%", fig.align='center', purl=FALSE}
include_graphics("../img/03_ram.jpg")
```

```{r harddrive2, echo=FALSE, out.width = "25%", fig.align='center', purl=FALSE}
include_graphics("../img/03_harddrive.jpg")
```


## Components of a computing environment

<center> *Why should we care?* </center>


## Big Data (Analytics)

- Need to understand how to *make best use of the available resources*, given a specific data analysis task.
     - CPU: Parallel processing (use all cores available)
     - RAM: Efficient memory allocation and usage
     - RAM + Mass Storage: Virtual memory, efficient swapping

## Insight from analyzing methods conceptually

- Methods for big data analytics come with an *'overhead'*
     - Additional 'preparatory' steps.
     - Only faster than traditional methods if data set has a certain size!

## Insight from analyzing methods conceptually

- Methods for big data analytics come with an *'overhead'*
     - Additional 'preparatory' steps.
     - Only faster than traditional methods if data set has a certain size!
- Examples: 
     - Uluru algorithm: Subsample, more steps, more lines of code than OLS.
     - Parallel processing: Distribute data/task, combine afterwards.
     - `fread`: Memory maps data before actually reading it into RAM.
     
     


## Beyond memory

 - RAM is not sufficient to handle the amount of data to be analyzed...
 - *What to do?*
 
## Beyond memory

 - RAM is not sufficient to handle the amount of data to be analyzed...
 - *What to do?*
 - Scale up by using parts of the available Mass Storage (hard-disk) as *virtual memory*
 


## Out-of-memory strategies

- Chunked data files on disk
- Memory-mapped files and shared memory

## Out-of-memory strategies

- Chunked data files on disk: `ff`-package
- Memory-mapped files and shared memory: `bigmemory`-package




## Chunking data with the `ff`-package

Preparations 
```{r message=FALSE}

# SET UP --------------

# install.packages(c("ff", "ffbase"))
# load packages
library(ff)
library(ffbase)
library(pryr)

# create directory for ff chunks, and assign directory to ff 
system("mkdir ffdf")
options(fftempdir = "ffdf")

```


## Chunking data with the `ff`-package

Import data, inspect change in RAM.

```{r echo=FALSE, message=FALSE, warning=FALSE}
gc()
```


```{r}
mem_change(
flights <- 
     read.table.ffdf(file="../data/flights.csv",
                     sep=",",
                     VERBOSE=TRUE,
                     header=TRUE,
                     next.rows=100000,
                     colClasses=NA)
)
```


## Chunking data with the `ff`-package

Inspect file chunks on disk and data structure in R environment.

```{r}
# show the files in the directory keeping the chunks
list.files("ffdf")

# investigate the structure of the object created in the R environment
summary(flights)
```



## Memory mapping with `bigmemory`

Preparations

```{r message=FALSE}

# SET UP ----------------

# load packages
library(bigmemory)
library(biganalytics)
```



## Memory mapping with `bigmemory`

Import data, inspect change in RAM.

```{r}
# import the data
flights <- read.big.matrix("../data/flights.csv",
                     type="integer",
                     header=TRUE,
                     backingfile="flights.bin",
                     descriptorfile="flights.desc")
```


## Memory mapping with `bigmemory`

Inspect the imported data.

```{r}
summary(flights)
```


## Memory mapping with `bigmemory`

Inspect the object loaded into the R environment.

```{r}
flights
```


## Memory mapping with `bigmemory`

- `backingfile`: The cache for the imported file (holds the raw data on disk).
- `descriptorfile`: Metadata describing the imported data set (also on disk).


## Memory mapping with `bigmemory`

Understanding the role of `backingfile` and `descriptorfile`.

First, import a large data set without a backing-file:

```{r}
# import data and check time needed  
system.time(
     flights1 <- read.big.matrix("../data/flights.csv",
                                 header = TRUE,
                                 sep = ",",
                                 type = "integer")
)

# import data and check memory used
mem_change(
     flights1 <- read.big.matrix("../data/flights.csv",
                                 header = TRUE,
                                 sep = ",",
                                 type = "integer")
)

flights1 
```




## Memory mapping with `bigmemory`

Understanding the role of `backingfile` and `descriptorfile`.

Second, import the same data set with a backing-file:

```{r}
# import data and check time needed  
system.time(
     flights2 <- read.big.matrix("../data/flights.csv",
                                 header = TRUE,
                                 sep = ",",
                                 type = "integer",
                                 backingfile = "flights2.bin",
                                 descriptorfile = "flights2.desc"
                                 )
)

# import data and check memory used
mem_change(
     flights2 <- read.big.matrix("../data/flights.csv",
                                 header = TRUE,
                                 sep = ",",
                                 type = "integer",
                                 backingfile = "flights2.bin",
                                 descriptorfile = "flights2.desc"
                                 )
)

flights2
```


## Memory mapping with `bigmemory`

Understanding the role of `backingfile` and `descriptorfile`.

Third, re-import the same data set with a backing-file.

```{r}
# remove the loaded file
rm(flights2)

# 'load' it via the backing-file
system.time(flights2 <- attach.big.matrix("flights2.desc"))

flights2

```




# The Tools: R, RStudio, GitHub, etc.

-----

```{r rstudio, echo=FALSE, out.width = "70%", fig.align='center', purl=FALSE}
include_graphics("../img/01_rstudio.png")
```


# Data Projects with GitHub

-----

```{r github, echo=FALSE, out.width = "70%", fig.align='center', purl=FALSE, fig.cap="Image by [jonobacon](https://www.flickr.com/photos/jonobacon/22160892602) ([CC BY 2.0](https://creativecommons.org/licenses/by/2.0/)) "}
include_graphics("../img/02_githublogo.gif")
```


## Version control with Git

- Keep track of your code.
- Develop in different branches.
- Safely go back to previous versions.

## Code repository on GitHub

- Work from different machines.
- Manage and document the project.
- Publish and collaborate. 


# Data Structures and Data Types

## R-tools to investigate structures and types

package | function | purpose
-------- | ---------- | ---------------------------------------------
`utils`  | `str()`    | Compactly display the structure of an arbitrary R object.
`base`   | `class()`   | Prints the class(es) of an R object.
`base`   | `typeof()`  | Determines the (R-internal) type or storage mode of an object.



## Structures to work with (in R)

We distinguish two basic characteristics:

  1. Data **types**: integers; real numbers ('numeric values', floating point numbers); text ('string', 'character values').

    
    
## Structures to work with (in R)

We distinguish two basic characteristics:

  1. Data **types**: integers; real numbers ('numeric values', floating point numbers); text ('string', 'character values').
  2. Basic **data structures** in RAM:
      - *Vectors*
      - *Factors*
      - *Arrays/Matrices*
      - *Lists*
      - *Data frames* (very `R`-specific)


## Data types: numeric

```{r}
a <- 1.5
b <- 3
```

R interprets this data as type `double` (class 'numeric'):

```{r}
typeof(a)
class(a)
```


## Data types: numeric


Given that these bytes of data are interpreted as numeric, we can use operators (here: math operators) that can work with such functions:

```{r}
a + b
```



## Data types: character


```{r}
a <- "1.5"
b <- "3"
```

```{r}
typeof(a)
class(a)
```


## Data types: character

Now the same line of code as above will result in an error:

```{r error=TRUE}
a + b
```



## Data structures: Vectors

```{r numvec, echo=FALSE, out.width = "10%", fig.align='center', fig.cap= "Illustration of a numeric vector (symbolic). Figure by @murrell_2009 (licensed under [CC BY-NC-SA 3.0 NZ](https://creativecommons.org/licenses/by-nc-sa/3.0/nz/)).", purl=FALSE}
include_graphics("../img/02_numvec.png")
```

## Data structures: Vectors

Example:

```{r}
persons <- c("Andy", "Brian", "Claire")
persons
```

```{r}
ages <- c(24, 50, 30)
ages
```


## Data structures: Factors

```{r factor, echo=FALSE, out.width = "10%", fig.align='center', fig.cap= "Illustration of a factor (symbolic). Figure by @murrell_2009 (licensed under [CC BY-NC-SA 3.0 NZ](https://creativecommons.org/licenses/by-nc-sa/3.0/nz/)).", purl=FALSE}
include_graphics("../img/02_factor.png")
```

## Data structures: Factors

Example:

```{r}
gender <- factor(c("Male", "Male", "Female"))
gender
```



## Data structures: Matrices/Arrays

```{r matrix, echo=FALSE, out.width = "20%", fig.align='center', fig.cap= "Illustration of a numeric matrix (symbolic). Figure by @murrell_2009 (licensed under [CC BY-NC-SA 3.0 NZ](https://creativecommons.org/licenses/by-nc-sa/3.0/nz/)).", purl=FALSE}
include_graphics("../img/02_matrix.png")
```


## Data structures: Matrices/Arrays

Example:

```{r}
my_matrix <- matrix(c(1,2,3,4,5,6), nrow = 3)
my_matrix

```

```{r}
my_array <- array(c(1,2,3,4,5,6), dim = 3)
my_array

```


## Data frames, tibbles, and data tables
 

```{r df, echo=FALSE, out.width = "20%", fig.align='center', fig.cap= "Illustration of a data frame (symbolic). Figure by @murrell_2009 (licensed under [CC BY-NC-SA 3.0 NZ](https://creativecommons.org/licenses/by-nc-sa/3.0/nz/)).", purl=FALSE}
include_graphics("../img/02_df.png")
```


## Data frames, tibbles, and data tables

Example: 

```{r}
df <- data.frame(person = persons, age = ages, gender = gender)
df

```


## Data structures: Lists

```{r list, echo=FALSE, out.width = "20%", fig.align='center', fig.cap= "Illustration of a list (symbolic). Figure by @murrell_2009 (licensed under [CC BY-NC-SA 3.0 NZ](https://creativecommons.org/licenses/by-nc-sa/3.0/nz/)).", purl=FALSE}
include_graphics("../img/02_list.png")
```


## Data structures: Lists

Example:

```{r}
my_list <- list(my_array, my_matrix, df)
my_list
```





# Programming with (Big) Data in R

## Typical Programming Tasks

- Procedures to import/export data.
- Procedures to clean and filter data.
- Implement functions for statistical analysis.

## Programming with Big Data

1. Which basic (already implemented) R functions are more or less suitable as building blocks for the program?
2. How can we exploit/avoid some of R's lower-level characteristics in order to implement efficient functions?
3. Is there a need to interface with a lower-level programming language in order to speed up the code? (advanced topic)

+ Independent of *how* we write a statistical procedure in R (or in any other language, for that matter), is there an *alternative statistical procedure/algorithm* that is faster but delivers approximately the same result.


## R-tools to investigate performance/resource allocation

package | function | purpose
-------- | ---------- | ---------------------------------------------
`utils`  | `object.size()` | Provides an estimate of the memory that is being used to store an R object.
`pryr`   | `object_size()` | Works similarly to `object.size()`, but counts more accurately and includes the size of environments.
`pryr` | `compare_size()` | Makes it easy to compare the output of object_size and object.size.
`pryr` | `mem_used()`     | Returns the total amount of memory (in megabytes) currently used by R.
`pryr` | `mem_change()`   | Shows the change in memory (in megabytes) before and after running code.
`base`   | `system.time()` | Returns CPU (and other) times that an R expression used.
`microbenchmark` | `microbenchmark()` | Highly accurate timing of R expression evaluation.
`profvis`| `profvis()`   | Profiles an R expression and visualizes the profiling data (usage of memory, time elapsed, etc.)



## Building blocks for programming with big data

- Several basic functions and packages that provide similar function. Which one to use?
- Example: Data import.
     - `utils::read.csv()` 
     - `data.table::fread()`

## Building blocks for programming with big data

```{r message=FALSE}
# read a CSV-file the 'traditional way'
flights <- read.csv("../data/flights.csv")
class(flights)

# alternative (needs the data.table package)
library(data.table)
flights <- fread("../data/flights.csv")
class(flights)

```

## Building blocks for programming with big data

```{r}
system.time(flights <- read.csv("../data/flights.csv"))
system.time(flights <- fread("../data/flights.csv"))
```

## Writing efficient code

- Memory allocation (before looping)
- Vectorization (different approaches)
- Beyond R

## Memory allocation before looping

```{r}
# naïve implementation
sqrt_vector <- 
     function(x) {
          output <- c()
          for (i in 1:length(x)) {
               output <- c(output, x[i]^(1/2))
          }
          
          return(output)
     }

```


## Memory allocation before looping

```{r}

# implementation with pre-allocation of memory
sqrt_vector_faster <- 
     function(x) {
          output <- rep(NA, length(x))
          for (i in 1:length(x)) {
               output[i] <-  x[i]^(1/2)
          }
          
          return(output)
     }

```


## Memory allocation before looping

*Test it!*

```{r}
# the different sizes of the vectors we will put into the two functions
input_sizes <- seq(from = 100, to = 10000, by = 100)
# create the input vectors
inputs <- sapply(input_sizes, rnorm)

# compute ouputs for each of the functions
output_slower <- 
     sapply(inputs, 
            function(x){ system.time(sqrt_vector(x))["elapsed"]
                 }
            )
output_faster <- 
     sapply(inputs, 
            function(x){ system.time(sqrt_vector_faster(x))["elapsed"]
                 }
            )
```

## Memory allocation before looping

*Test it!*

```{r}
# load packages
library(ggplot2)

# initiate data frame for plot
plotdata <- data.frame(time_elapsed = c(output_slower, output_faster),
                       input_size = c(input_sizes, input_sizes),
                       Implementation= c(rep("sqrt_vector", length(output_slower)),
                            rep("sqrt_vector_faster", length(output_faster))))

```


## Memory allocation before looping

*Test it!*

```{r}
# plot
ggplot(plotdata, aes(x=input_size, y= time_elapsed)) +
     geom_point(aes(colour=Implementation)) +
     theme_minimal(base_size = 18) +
     ylab("Time elapsed (in seconds)") +
     xlab("No. of elements processed")
     
```



## Vectorization 

- "In R, everything is a vector..."
- Directly operate on vectors, not elements.
- Avoid unnecessary repetition of 'preparatory steps'.

## Vectorization: Example 

```{r}
# implementation with vectorization
sqrt_vector_fastest <- 
     function(x) {
               output <-  x^(1/2)
          return(output)
     }

# speed test
output_fastest <- 
     sapply(inputs, 
            function(x){ system.time(sqrt_vector_fastest(x))["elapsed"]
                 }
            )
```

## Vectorization: Example 

*Test it!*

```{r}
# load packages
library(ggplot2)

# initiate data frame for plot
plotdata <- data.frame(time_elapsed = c(output_faster, output_fastest),
                       input_size = c(input_sizes, input_sizes),
                       Implementation= c(rep("sqrt_vector_faster", length(output_faster)),
                            rep("sqrt_vector_fastest", length(output_fastest))))
 
```


## Vectorization: Example 

*Test it!*

```{r}
# plot
ggplot(plotdata, aes(x=input_size, y= time_elapsed)) +
     geom_point(aes(colour=Implementation)) +
     theme_minimal(base_size = 18) +
     ylab("Time elapsed (in seconds)") +
     xlab("No. of elements processed")
     
```



## Vectorization: `apply`-type functions vs loops

- Apply a function to each element of a vector/list.
- For example, `lapply()`. 

## Example

- Read several data files into R.
- Example data source: [Health News in Twitter Data Set](https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter) by @karami_etal2017.
- Loop vs `lapply()`, vs `Vectorization()`

## Example: Preparations

```{r message=FALSE}
# load packages
library(data.table)

# get a list of all file-paths
textfiles <- list.files("../data/twitter_texts", full.names = TRUE)

```

## Example: `for`-loop approach

```{r message=FALSE, warning=FALSE}
# prepare loop
all_texts <- list()
n_files <- length(textfiles)
length(all_texts) <- n_files
# read all files listed in textfiles
for (i in 1:n_files) {
     all_texts[[i]] <- fread(textfiles[i])
}

```

## Example: `for`-loop approach

*Check the results*

```{r}
# combine all in one data.table
twitter_text <- rbindlist(all_texts)
# check result
str(twitter_text)

```

## Example: `lapply` approach

```{r message=FALSE, warning=FALSE}
# prepare loop
all_texts <- lapply(textfiles, fread)
# combine all in one data.table
twitter_text <- rbindlist(all_texts)
# check result
str(twitter_text)

```


## Example: `Vectorization` approach

```{r message=FALSE, warning=FALSE}
# initiate the import function
import_file <- 
     function(x) {
          parsed_x <- fread(x)
          return(parsed_x)
     }

# 'vectorize' it
import_files <- Vectorize(import_file, SIMPLIFY = FALSE)
```


## Example: `Vectorization` approach

```{r message=FALSE, warning=FALSE}
# Apply the vectorized function
all_texts <- import_files(textfiles)
twitter_text <- rbindlist(all_texts)
# check the result
str(twitter_text)
```


## R, beyond R

- For advanced programmers, R offers various options to directly make use of compiled programs (for example, written in C, C++, or FORTRAN). 
- Several of the core R functions are implemented in one of these lower-level programming languages.

## R, beyond R

*Have a look at a function's source code!* 

```{r}
import_file
```

## R, beyond R

*Have a look at a function's source code!* 

```{r}
sum
```





## References {.smaller}

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>
